<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8" />
  <meta name="description" content="TableBench: A Comprehensive and Complex Benchmark for Table Question Answering" />
  <meta name="keywords"
    content="Table Question Answering, Table QA, Large Language Models, LLM, Table QA Evaluation, Benchmark" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>
    TableBench Homepage
  </title>
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet" />

  <link rel="stylesheet" href="./css/bulma.min.css" />
  <link rel="stylesheet" href="./css/bulma-carousel.min.css" />
  <link rel="stylesheet" href="./css/bulma-slider.min.css" />
  <link rel="stylesheet" href="./css/fontawesome.all.min.css" />
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css" />
  <link rel="stylesheet" href="./css/index.css" />
  <link rel="icon" href="./images/favicon.svg" />

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./js/fontawesome.all.min.js"></script>
  <script src="./js/bulma-carousel.min.js"></script>
  <script src="./js/bulma-slider.min.js"></script>
  <script src="./js/index.js"></script>
</head>

<body>

  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">
              TableBench: A Comprehensive and Complex Benchmark for Table Question Answering
            </h1>

            <div class="is-size-5 publication-authors">
              <span class="author-block">
                <a href="">Xianjie Wu</a><sup>1</sup>,</span>
              <span class="author-block">
                <a href="">Jian Yang</a><sup>1</sup>,</span>
              <span class="author-block">
                <a href="">Linzheng Chai</a><sup>1</sup>,</span>
              <span class="author-block">
                <a href="">Ge Zhang</a><sup>2</sup>,</span>
              <span class="author-block">
                <a href="">Jiaheng Liu</a><sup>1</sup>,</span>
              <span class="author-block">
                <a href="">Xeron Du</a><sup>2</sup>,</span>
              <span class="author-block">
                <a href="">Di Liang</a><sup>3</sup>,</span>
              <span class="author-block">
                <a href="">Daixin Shu</a><sup>1</sup>,</span>
              <span class="author-block">
                <a href="">Xianfu Cheng</a><sup>1</sup>,</span>
              <span class="author-block">
                <a href="">Tianzhen Sun</a><sup>1</sup>,</span>
              <span class="author-block">
                <a href="">Tongliang Li</a><sup>4</sup>,</span>
              <span class="author-block">
                <a href="">Zhoujun Li</a><sup>1</sup>,</span>
              <span class="author-block">
                <a href="">Guanglin Niu</a><sup>1</sup>,</span>
            </div>
            <div class="is-size-5 publication-authors">
              <span class="author-block"><sup>1</sup>CCSE, Beihang University</span>
              <span class="author-block"><sup>2</sup>University of Waterloo</span>
              <span class="author-block"><sup>3</sup>Fudan University</span>
              <span class="author-block"><sup>4</sup>Beijing Information Science and Technology University</span>
            </div>

            <div class="column has-text-centered">
              <div class="publication-links">
                <!-- PDF Link. -->
                <span class="link-block">
                  <a href="https://www.arxiv.org/abs/2408.09174"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                    </span>
                    <span>Paper</span>
                  </a>
                </span>
                <span class="link-block">
                  <a href="https://github.com/TableBench/TableBench"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>
                <!-- TableBench Link. -->
                <span class="link-block">
                  <a href="https://huggingface.co/datasets/Multilingual-Multimodal-NLP/TableBench"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="far fa-images"></i>
                    </span>
                    <span>TableBench</span>
                  </a>
                </span>
                <!-- TableInstruct Link. -->
                <span class="link-block">
                  <a href="https://huggingface.co/datasets/Multilingual-Multimodal-NLP/TableBench-Instruct"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="far fa-images"></i>
                    </span>
                    <span>TableInstruct</span>
                  </a>
                  <!-- TableLLM Link. -->
                  <span class="link-block">
                    <a href="https://huggingface.co/collections/Multilingual-Multimodal-NLP/tablebench-6698d0b29a21ed71c819f30e"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="far fa-images"></i>
                      </span>
                      <span>TableLLMs</span>
                    </a>
                  </span>
                  <!-- Leaderboard Link. -->
                  <span class="link-block">
                    <a href="leaderboard.html" class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fa fa-trophy"></i>
                      </span>
                      <span>Leaderboard</span>
                    </a>
                  </span>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
  </section>

  <section class="hero teaser">
    <div class="container is-max-desktop">
      <div class="hero-body">
        <div class="columns is-centered">
          <!-- center the image -->
          <img src="./images/intro_case.png" alt="Teaser" class="teaser-image center" width="60%" />
        </div>
      </div>
    </div>
  </section>


  <section class="section">
    <div class="container is-max-desktop">
      <!-- Abstract. -->
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Introduction</h2>
          <div class="content has-text-justified">
            <p>
              Recent advancements in Large Language Models (LLMs) have markedly enhanced the interpretation and
              processing of tabular data, introducing previously unimaginable capabilities. Despite these achievements,
              LLMs still encounter significant challenges when applied in industrial scenarios, particularly due to the
              increased complexity of reasoning required with real-world tabular data, underscoring a notable disparity
              between academic benchmarks and practical applications. To address this discrepancy, we conduct a detailed
              investigation into the application of tabular data in industrial scenarios and propose a comprehensive and
              complex benchmark TableBench, including 18 fields within four major categories of table question answering
              (TableQA) capabilities. Furthermore, we introduce TableLLM, trained on our meticulously constructed
              training set TableInstruct, achieving comparable performance with GPT-3.5. Massive experiments conducted
              on TableBench indicate that both open-source and proprietary LLMs still have significant room for
              improvement to meet real-world demands, where the most advanced model, GPT-4, achieves only a modest score
              compared to humans.
            </p>
          </div>
        </div>
      </div>
      <!--/ Abstract. -->
    </div>
  </section>

  <section class="section">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Dataset Construction</h2>
          <div class="content has-text-justified">
            <div class="columns is-centered">
              <img src="./images/annotation_process.png" alt="Dataset Construction" class="teaser-image center"
                width="98%" height="100%" />
            </div>
            <p>
              To bridge the gap between academic benchmarks and industrial scenarios, we comprehensively analyze tabular
              data applications in real-world contexts, categorizing these problems into four major categories and 18
              specific subcategories. We define the complexity of these tasks based on the reasoning steps required for
              problem-solving and provide detailed guidelines for defining and decomposing these steps, which are
              rigorously followed during the annotation process. Additionally, we introduce an annotation framework that
              combines manual and automated methods to enhance annotation efficiency, as illustrated in Figure. Finally,
              we propose two high-quality corpora: TableBench, a comprehensive and complex benchmark consisting of 886
              samples, and TableInstruct (20K samples in total), massive instruction corpora designed to instruct LLMs
              with various reasoning methods.
            </p>
          </div>
        </div>
      </div>
  </section>
  <section class="section">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Dataset Statistic</h2>
          <div class="content has-text-justified">
            <div class="columns is-centered">
              <div class="image-container">
                <img src="./images/overview_of_tablebench.png" alt="Overview of TableBench" class="teaser-image left" />
                <div class="right-images">
                  <img src="./images/reasoning_steps_analysis.png" alt="Reasoning Steps Analysis"
                    class="teaser-image" />
                  <img src="./images/categories.png" alt="Dataset Topics" class="teaser-image" />

                </div>
              </div>
            </div>
            <h4>
              Question Categories
            </h4>
            <p>
              Drawing from real-world scenarios and user demands for tabular data, we devise four primary question
              categories: fact-checking, numerical reasoning, data analysis, and visualization, encompassing 18
              subcategories, thoroughly illustrating the various challenges encountered in TableQA scenarios.
              Compared with existing datasets, TableBench encompasses a broader spectrum of question categories as
              presented in Table, with a particular emphasis on data analysis and chart generation capabilities that are
              notably scarce in prior datasets.
            </p>
            <h4>
              Reasoning Steps
            </h4>
            <p>
              We define the complexity of the dataset by calculating the number of reasoning steps required to solve the
              problem. Figure demonstrates that the overall complexity of TableBench is significantly higher than that
              of existing datasets, particularly in questions about data analysis and visualization. .
            </p>
          </div>
        </div>
      </div>
  </section>
  <section class="section">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Overall Performance</h2>
          <div class="content has-text-justified">
            <div class="columns is-centered">
              <img src="./images/overall_results.png" alt="Dataset Statistic" class="teaser-image center" width="100%"
                height="80%" />
            </div>
            <div class="columns is-centered">
              <img src="./images/reasoning_methods_analysis.png" alt="Dataset Statistic" class="teaser-image center"
                width="100%" height="80%" />
            </div>
            <p>
              We evaluate 30+ models with sizes ranging from 7B to 110B parameters, including general/code LLMs,
              open-source/proprietary models, and SFT models.
              We explore three distinct reasoning methodologies to augment the reasoning capabilities for tabular data:
              Textual Chain of Thought (TCoT), Symbolic Chain of Thought (SCoT), and Program of Thought (PoT).
              TCoT utilizes a textual reasoning approach, employing a series of inferential steps to deduce the final
              answer.
              SCoT adopts symbolic reasoning steps, leveraging programming language commands to iteratively simulate and
              refine results through a 'Think then Code' process.
              Conversely, PoT involves generating executable code, employing lines of code as reasoning steps within a
              programming environment to achieve results.
            </p>
          </div>
        </div>
      </div>
  </section>
  <section class="section">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Further Analysis</h2>
          <div class="content has-text-justified">
            <div class="columns is-centered">
              <img src="./images/effect_of_parsing_ratio.png" alt="Dataset Statistic" class="teaser-image center"
                width="50%" height="80%" />
              <img src="./images/data_efficient.png" alt="Dataset Statistic" class="teaser-image center" width="50%"
                height="80%" />
            </div>
            <h4>
              Effect of Parsing Ratio
            </h4>
            <p>
              In comparison to the DP, SCoT, and TCoT methods in Figure above, the data points on the left side of the quadratic curve show that at low parsing ratios, the overall score increases as the parsing ratio decreases, suggesting that certain models (e.g., StructLLM), possess strong table understanding capabilities but exhibit weaker instruction-following abilities. This may be attributed to differences in the instruction format during instruction tuning compared to the format we employ. 
              The right side of the quadratic curve reveals that despite the strong instruction-following performance of the DP method, the non-reasoning DP method faces a clear performance ceiling. In contrast, reasoning-based methods show significant potential for improvement.
              The curve of the PoT highlights the substantial potential of the PoT to enhance the overall score by increasing the parsing rate.
            </p>
            <h4>
              Data Efficiency of TableInstruct
            </h4>
            <p>
              We construct datasets of varying sizes by sampling from TableInstruct with sampling rates ranging from 0.2 to 0.6. Figure above visually depicts the relative performance at different sampling rates. Surprisingly, with only 60% of the samples, the model retains over 90% of the performance of the complete dataset. 
              The full data provides the highest knowledge coverage, enabling the model to achieve optimal overall performance, comparable to GPT-3.5, with inference costs being only a fraction, indicating the high efficiency of TableInstruct.
            </p>


          </div>
        </div>
      </div>
  </section>


  <footer class="footer">
    <div class="container">

      <div class="columns is-centered">
        <div class="column is-8">
          <div class="content">
            <p>
              Please reach out to <a href="wuxianjie@buaa.edu.cn">wuxianjie@buaa.edu.cn</a> for questions or
              feedback on TableBench. We are also open to collaborations and suggestions for new scenarios to add to
              the benchmark.
            </p>
            <p>
              The source code from this website is borrowed from <a
                href="https://github.com/LiveCodeBench/livecodebench.github.io">LiveCodeBench</a>!
            </p>
          </div>
        </div>
      </div>
    </div>
  </footer>
</body>

</html>